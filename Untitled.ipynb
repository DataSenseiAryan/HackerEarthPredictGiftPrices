{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import date\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular import add_datepart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../HackerEarthPredictGiftPrices/dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gift_id</th>\n",
       "      <th>gift_type</th>\n",
       "      <th>gift_category</th>\n",
       "      <th>gift_cluster</th>\n",
       "      <th>instock_date</th>\n",
       "      <th>stock_update_date</th>\n",
       "      <th>lsg_1</th>\n",
       "      <th>lsg_2</th>\n",
       "      <th>lsg_3</th>\n",
       "      <th>lsg_4</th>\n",
       "      <th>lsg_5</th>\n",
       "      <th>lsg_6</th>\n",
       "      <th>uk_date1</th>\n",
       "      <th>uk_date2</th>\n",
       "      <th>is_discounted</th>\n",
       "      <th>volumes</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GF_11156</td>\n",
       "      <td>61</td>\n",
       "      <td>534</td>\n",
       "      <td>3942</td>\n",
       "      <td>2014-02-21 05:07:06.000</td>\n",
       "      <td>2016-11-09 15:49:51.000</td>\n",
       "      <td>3377</td>\n",
       "      <td>5221</td>\n",
       "      <td>504</td>\n",
       "      <td>1912</td>\n",
       "      <td>10</td>\n",
       "      <td>554</td>\n",
       "      <td>2014-02-24 08:07:06.000</td>\n",
       "      <td>2014-02-24 07:07:06.000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GF_11157</td>\n",
       "      <td>61</td>\n",
       "      <td>534</td>\n",
       "      <td>3942</td>\n",
       "      <td>2014-02-21 06:07:06.000</td>\n",
       "      <td>2016-11-11 13:49:51.000</td>\n",
       "      <td>3377</td>\n",
       "      <td>5221</td>\n",
       "      <td>504</td>\n",
       "      <td>1912</td>\n",
       "      <td>10</td>\n",
       "      <td>554</td>\n",
       "      <td>2014-02-22 07:07:06.000</td>\n",
       "      <td>2014-02-24 06:07:06.000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GF_15689</td>\n",
       "      <td>584</td>\n",
       "      <td>262</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-02-21 09:30:21.000</td>\n",
       "      <td>2016-03-24 14:46:18.000</td>\n",
       "      <td>5290</td>\n",
       "      <td>1579</td>\n",
       "      <td>3203</td>\n",
       "      <td>1912</td>\n",
       "      <td>9</td>\n",
       "      <td>1578</td>\n",
       "      <td>2016-01-26 00:04:45.000</td>\n",
       "      <td>2016-03-18 02:00:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GF_11155</td>\n",
       "      <td>61</td>\n",
       "      <td>534</td>\n",
       "      <td>3942</td>\n",
       "      <td>2014-02-22 05:07:06.000</td>\n",
       "      <td>2016-11-10 16:49:51.000</td>\n",
       "      <td>3377</td>\n",
       "      <td>5221</td>\n",
       "      <td>504</td>\n",
       "      <td>1912</td>\n",
       "      <td>10</td>\n",
       "      <td>554</td>\n",
       "      <td>2016-11-07 13:49:51.000</td>\n",
       "      <td>2016-11-06 04:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GF_11158</td>\n",
       "      <td>61</td>\n",
       "      <td>534</td>\n",
       "      <td>3942</td>\n",
       "      <td>2014-02-22 07:07:06.000</td>\n",
       "      <td>2016-11-10 13:49:51.000</td>\n",
       "      <td>3377</td>\n",
       "      <td>5221</td>\n",
       "      <td>504</td>\n",
       "      <td>1912</td>\n",
       "      <td>9</td>\n",
       "      <td>554</td>\n",
       "      <td>2016-11-07 15:49:51.000</td>\n",
       "      <td>2016-11-06 01:00:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gift_id  gift_type  gift_category  gift_cluster             instock_date  \\\n",
       "0  GF_11156         61            534          3942  2014-02-21 05:07:06.000   \n",
       "1  GF_11157         61            534          3942  2014-02-21 06:07:06.000   \n",
       "2  GF_15689        584            262             0  2014-02-21 09:30:21.000   \n",
       "3  GF_11155         61            534          3942  2014-02-22 05:07:06.000   \n",
       "4  GF_11158         61            534          3942  2014-02-22 07:07:06.000   \n",
       "\n",
       "         stock_update_date  lsg_1  lsg_2  lsg_3  lsg_4  lsg_5  lsg_6  \\\n",
       "0  2016-11-09 15:49:51.000   3377   5221    504   1912     10    554   \n",
       "1  2016-11-11 13:49:51.000   3377   5221    504   1912     10    554   \n",
       "2  2016-03-24 14:46:18.000   5290   1579   3203   1912      9   1578   \n",
       "3  2016-11-10 16:49:51.000   3377   5221    504   1912     10    554   \n",
       "4  2016-11-10 13:49:51.000   3377   5221    504   1912      9    554   \n",
       "\n",
       "                  uk_date1                 uk_date2  is_discounted  volumes  \\\n",
       "0  2014-02-24 08:07:06.000  2014-02-24 07:07:06.000              0      NaN   \n",
       "1  2014-02-22 07:07:06.000  2014-02-24 06:07:06.000              1      NaN   \n",
       "2  2016-01-26 00:04:45.000  2016-03-18 02:00:00.000              1      NaN   \n",
       "3  2016-11-07 13:49:51.000  2016-11-06 04:00:00.000              0      NaN   \n",
       "4  2016-11-07 15:49:51.000  2016-11-06 01:00:00.000              1      NaN   \n",
       "\n",
       "    price  \n",
       "0  175.54  \n",
       "1   95.80  \n",
       "2  107.35  \n",
       "3  172.90  \n",
       "4   77.72  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gift_type</th>\n",
       "      <th>gift_category</th>\n",
       "      <th>gift_cluster</th>\n",
       "      <th>lsg_1</th>\n",
       "      <th>lsg_2</th>\n",
       "      <th>lsg_3</th>\n",
       "      <th>lsg_4</th>\n",
       "      <th>lsg_5</th>\n",
       "      <th>lsg_6</th>\n",
       "      <th>is_discounted</th>\n",
       "      <th>volumes</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20279.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "      <td>7323.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>739.554662</td>\n",
       "      <td>394.171557</td>\n",
       "      <td>3303.358548</td>\n",
       "      <td>5314.595345</td>\n",
       "      <td>4187.653928</td>\n",
       "      <td>4866.945510</td>\n",
       "      <td>1679.152226</td>\n",
       "      <td>8.652695</td>\n",
       "      <td>1265.898171</td>\n",
       "      <td>0.229646</td>\n",
       "      <td>15.515363</td>\n",
       "      <td>143.404411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>389.216989</td>\n",
       "      <td>235.077769</td>\n",
       "      <td>2541.082549</td>\n",
       "      <td>2703.317282</td>\n",
       "      <td>2274.875522</td>\n",
       "      <td>2713.856392</td>\n",
       "      <td>485.699119</td>\n",
       "      <td>2.349388</td>\n",
       "      <td>697.838495</td>\n",
       "      <td>0.420616</td>\n",
       "      <td>7.579669</td>\n",
       "      <td>267.281159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>403.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>587.000000</td>\n",
       "      <td>3311.000000</td>\n",
       "      <td>2251.000000</td>\n",
       "      <td>2548.000000</td>\n",
       "      <td>1801.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>577.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>45.645000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>825.000000</td>\n",
       "      <td>433.000000</td>\n",
       "      <td>3231.000000</td>\n",
       "      <td>5520.000000</td>\n",
       "      <td>4246.000000</td>\n",
       "      <td>4839.000000</td>\n",
       "      <td>1912.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1616.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>75.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1032.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>5787.000000</td>\n",
       "      <td>7535.000000</td>\n",
       "      <td>6504.500000</td>\n",
       "      <td>7387.000000</td>\n",
       "      <td>1912.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1899.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>126.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1360.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>7567.000000</td>\n",
       "      <td>9979.000000</td>\n",
       "      <td>7604.000000</td>\n",
       "      <td>9493.000000</td>\n",
       "      <td>2056.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>7010.270000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gift_type  gift_category  gift_cluster         lsg_1         lsg_2  \\\n",
       "count  20279.000000   20279.000000  20279.000000  20279.000000  20279.000000   \n",
       "mean     739.554662     394.171557   3303.358548   5314.595345   4187.653928   \n",
       "std      389.216989     235.077769   2541.082549   2703.317282   2274.875522   \n",
       "min        1.000000       1.000000      0.000000      0.000000      0.000000   \n",
       "25%      403.000000     188.000000    587.000000   3311.000000   2251.000000   \n",
       "50%      825.000000     433.000000   3231.000000   5520.000000   4246.000000   \n",
       "75%     1032.000000     534.000000   5787.000000   7535.000000   6504.500000   \n",
       "max     1360.000000     893.000000   7567.000000   9979.000000   7604.000000   \n",
       "\n",
       "              lsg_3         lsg_4         lsg_5         lsg_6  is_discounted  \\\n",
       "count  20279.000000  20279.000000  20279.000000  20279.000000   20279.000000   \n",
       "mean    4866.945510   1679.152226      8.652695   1265.898171       0.229646   \n",
       "std     2713.856392    485.699119      2.349388    697.838495       0.420616   \n",
       "min        0.000000      3.000000      0.000000      0.000000       0.000000   \n",
       "25%     2548.000000   1801.000000      9.000000    577.500000       0.000000   \n",
       "50%     4839.000000   1912.000000      9.000000   1616.000000       0.000000   \n",
       "75%     7387.000000   1912.000000     10.000000   1899.000000       0.000000   \n",
       "max     9493.000000   2056.000000     10.000000   2065.000000       1.000000   \n",
       "\n",
       "           volumes         price  \n",
       "count  7323.000000  20279.000000  \n",
       "mean     15.515363    143.404411  \n",
       "std       7.579669    267.281159  \n",
       "min       5.000000      0.010000  \n",
       "25%       9.000000     45.645000  \n",
       "50%      13.000000     75.600000  \n",
       "75%      24.000000    126.845000  \n",
       "max      29.000000   7010.270000  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingcheck(data):\n",
    "    total = data.isnull().sum().sort_values(ascending=False)\n",
    "    percent_1 = data.isnull().sum()/data.isnull().count()*100\n",
    "    percent_2 = (np.round(percent_1, 1)).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%']) #ptr\n",
    "    return missing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>volumes</th>\n",
       "      <td>12956</td>\n",
       "      <td>63.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsg_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gift_type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gift_category</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gift_cluster</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instock_date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock_update_date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsg_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsg_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsg_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsg_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsg_6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk_date1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk_date2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_discounted</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gift_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Total     %\n",
       "volumes            12956  63.9\n",
       "price                  0   0.0\n",
       "lsg_2                  0   0.0\n",
       "gift_type              0   0.0\n",
       "gift_category          0   0.0\n",
       "gift_cluster           0   0.0\n",
       "instock_date           0   0.0\n",
       "stock_update_date      0   0.0\n",
       "lsg_1                  0   0.0\n",
       "lsg_3                  0   0.0\n",
       "lsg_4                  0   0.0\n",
       "lsg_5                  0   0.0\n",
       "lsg_6                  0   0.0\n",
       "uk_date1               0   0.0\n",
       "uk_date2               0   0.0\n",
       "is_discounted          0   0.0\n",
       "gift_id                0   0.0"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missingcheck(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df.drop( ['volumes'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['instock_date'] = pd.to_datetime(dff['instock_date'] ,errors='coerce')\n",
    "dff['justinstock_date'] = dff['instock_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['stock_update_date'] = pd.to_datetime(dff['stock_update_date'] ,errors='coerce')\n",
    "dff['juststock_update_date'] = dff['stock_update_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['uk_date1'] = pd.to_datetime(dff['uk_date1'] ,errors='coerce')\n",
    "dff['justuk_date1'] = dff['uk_date1'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['uk_date2'] = pd.to_datetime(dff['uk_date2'] ,errors='coerce')\n",
    "dff['justuk_date2'] = dff['uk_date2'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of days gift was in stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['DaysStockUpdate'] = (dff['stock_update_date']- dff['instock_date']).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no of days between order1 and order2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['buyer12diff'] = (dff['uk_date1']-dff['uk_date2']).dt.days\n",
    "dff['buyer12diff'] = np.absolute(dff['buyer12diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at order1 time was gift in stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['buy1buytime'] = (dff['uk_date1'] -dff['instock_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12967     -5\n",
       "11146     -5\n",
       "18180     -5\n",
       "6231      -5\n",
       "10812     -5\n",
       "        ... \n",
       "47       881\n",
       "12       897\n",
       "8        986\n",
       "3        989\n",
       "4        989\n",
       "Name: buy1buytime, Length: 20279, dtype: int64"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff['buy1buytime'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order 2 in stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['buy2buytime'] = (dff['uk_date2'] -dff['instock_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16939   -585\n",
       "17729   -583\n",
       "18807   -582\n",
       "18470   -579\n",
       "19393   -579\n",
       "        ... \n",
       "61       871\n",
       "47       877\n",
       "12       892\n",
       "4        987\n",
       "3        987\n",
       "Name: buy2buytime, Length: 20279, dtype: int64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff['buy2buytime'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stockupdate date differece "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['stockupdatediff1'] = (dff['stock_update_date'] - dff['uk_date1']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['stockupdatediff2'] = (dff['stock_update_date'] - dff['uk_date2']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datepart(df, fldname, drop=True):\n",
    "    fld = df[fldname]\n",
    "    if not np.issubdtype(fld.dtype, np.datetime64):\n",
    "        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n",
    "    targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
    "    \n",
    "#     for n in ('Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n",
    "#             'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start'):\n",
    "    \n",
    "    for n in ('Year', 'Month', 'Week', 'Day','Hour', 'Dayofweek', 'Dayofyear',\n",
    "            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start'):\n",
    "        df[targ_pre+n] = getattr(fld.dt,n.lower())\n",
    "    df[targ_pre+'Elapsed'] = fld.astype(np.int64) // 10**9\n",
    "    if drop: df.drop(fldname, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_datepart(dff, 'instock_date',drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_datepart(dff, 'stock_update_date',drop =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_datepart(dff, 'uk_date1', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_datepart(dff, 'uk_date2', drop= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-11-12 13:48:30')"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff['instock_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-04-21 01:49:50')"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff['stock_update_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-04-17 16:14:57.904000')"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff['uk_date2'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "### was it a holiday or not instockdate, stockupdateday,ukdate1,ukdate2\n",
    "time = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = dff['instock_date'].min()\n",
    "\n",
    "# end = dff['stock_update_date'].max()\n",
    "\n",
    "# time['date'] = pd.date_range(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uk_holidays=[]\n",
    "# for holiday in holidays.UK(years=[2014,2015,2016]).items():\n",
    "#     uk_holidays.append(str(holiday[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#uk_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dff['Isholidayinstock']= [ 1 if str(val).split()[0] in uk_holidays else 0 for val in dff['instock_date']]\n",
    "# dff['Isholidaystockupdate']= [ 1 if str(val).split()[0] in uk_holidays else 0 for val in dff['stock_update_date']]\n",
    "# dff['IsholidayUkdate1']= [ 1 if str(val).split()[0] in uk_holidays else 0 for val in dff['uk_date1']]\n",
    "# dff['IsholidayUkdate2']= [ 1 if str(val).split()[0] in uk_holidays else 0 for val in dff['uk_date2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### grace period dates ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_graceholiday=[]\n",
    "for holiday in holidays.UK(years=[2014,2015,2016]).items():\n",
    "    uk_graceholiday.append(holiday[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "graceondate=[]\n",
    "for i in uk_graceholiday:\n",
    "    twodayago = i - timedelta(days = 3)\n",
    "    twodayafter = i + timedelta(days = 3)\n",
    "    for date in pd.date_range(twodayago,twodayafter):\n",
    "        graceondate.append((str(date).split()[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_graceperiod = list(set(graceondate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['Isholidayinstockgrceperiod']= [ 1 if str(val).split()[0] in uk_graceperiod else 0 for val in dff['instock_date']]\n",
    "dff['Isholidaystock_update_dategrceperiod']= [ 1 if str(val).split()[0] in uk_graceperiod else 0 for val in dff['stock_update_date']]\n",
    "dff['IsholidayUk_date1grceperiod']= [ 1 if str(val).split()[0] in uk_graceperiod else 0 for val in dff['uk_date1']]\n",
    "dff['IsholidayUk_date2grceperiod']= [ 1 if str(val).split()[0] in uk_graceperiod else 0 for val in dff['uk_date2']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('lsg_1', 'lsg_2')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('lsg_1', 'lsg_2')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-341-6cc592d721fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lsg_1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lsg_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#,'lsg_3','lsg_4','lsg_5','lsg_6']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('lsg_1', 'lsg_2')"
     ]
    }
   ],
   "source": [
    "dff['lsg_1','lsg_2']#,'lsg_3','lsg_4','lsg_5','lsg_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('lsg_1', 'lsg_2', 'lsg_3', 'lsg_4', 'lsg_5', 'lsg_6')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('lsg_1', 'lsg_2', 'lsg_3', 'lsg_4', 'lsg_5', 'lsg_6')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-338-63d9350ce02b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lsg_1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lsg_2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lsg_3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lsg_4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lsg_5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lsg_6'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# statistics of scaled data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('lsg_1', 'lsg_2', 'lsg_3', 'lsg_4', 'lsg_5', 'lsg_6')"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(df['lsg_1','lsg_2','lsg_3','lsg_4','lsg_5','lsg_6'])\n",
    "\n",
    "# statistics of scaled data\n",
    "pd.DataFrame(data_scaled).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
